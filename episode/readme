1. download the dataset 'all_posts.csv'. It is too large to upload here, one can find it through this link: https://drive.google.com/open?id=0Bz-4FukuZM1KQlVlRThBcU0tRkE
2. After the data is downloaded, create the following folders inside of 'episode' folder:
- configure configure is used to store the parameters of the word2vec models.
- doc_vec doc_vec is to store the document vectors for all questions posts in all_posts.cvs.
- word_vec word_vec is to store the word vectors for all unique words in the word2vec models.
- episode_vec episode_vec is to store the document vectors for all episode descriptions.
- model model is used to store the word2vec model.
- text text is to store the body of all question posts and all answer posts. Also it stores the episode descritions.
- vocab_dict vocab_dict is to store the vocabularies for different word2vec models.

3. Run 'gensim_models_question_answer python3.ipynb' to train word vectors and doc vectors. Here the doc vectors are for the quesitons posts. 
4. Run 'Cos similarity.ipynb' to find similar or related questions in the stack overflow (SO).
4'.Run 'Episode Recommendation  python3.ipynb' to build docvec for each episode description using the word vectors generated from SO.


